{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/match_data.csv')\n",
    "X1 = df1.drop(columns=['Date', 'Team1', 'Team2', 'Score'])\n",
    "y1 = df1['Score']\n",
    "ds1_name = \"match_data\"\n",
    "\n",
    "df2 = pd.read_csv('../data/cleaned_rounds_data.csv')\n",
    "df2 = df2.drop(columns=[f'player_{i}_{suffix}' for i in range(1, 11) for suffix in ['team_name', 'name']])\n",
    "X2 = df2.drop(['round_winner'], axis=1)\n",
    "y2 = df2['round_winner']\n",
    "ds2_name = \"rounds_data\"\n",
    "\n",
    "df3 = pd.read_csv('../data/cleaned_rounds_data_with_stats.csv')\n",
    "df3 = df3.drop(columns=[f'player_{i}_{suffix}' for i in range(1, 11) for suffix in ['team_name', 'name']])\n",
    "X3 = df3.drop(['round_winner'], axis=1)\n",
    "y3 = df3['round_winner']\n",
    "ds3_name = \"rounds_data_with_stats\"\n",
    "\n",
    "datasets = [(X1, y1, ds1_name), (X2, y2, ds2_name), (X3, y3, ds3_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.0005, 0.0001]\n",
    "dropout_rate = [0.3, 0.4, 0.5]\n",
    "l2_reg = [0.01, 0.001, 0.0001]\n",
    "batch_size = [32, 64, 128]\n",
    "epochs = [100, 200, 300, 500, 750, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_data: new best accuracy: 0.60665363073349, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 100\n",
      "match_data: new best accuracy: 0.6203522682189941, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 300\n",
      "match_data: new best accuracy: 0.6223092079162598, learning rate: 0.001, dropout rate: 0.4, l2: 0.0001, batch size: 128, epochs: 1000\n",
      "match_data: new best accuracy: 0.6301369667053223, learning rate: 0.001, dropout rate: 0.5, l2: 0.0001, batch size: 64, epochs: 500\n",
      "Dataset: match_data, Accuracy: 0.6203522682189941, Best_LR: 0.001, Best_Dropout: 0.5, Best_L2: 0.0001, Best_BS: 64, Best_Epochs: 500, Duration: 3891.7956733703613\n",
      "rounds_data: new best accuracy: 0.7697903513908386, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 100\n",
      "rounds_data: new best accuracy: 0.7732135057449341, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 200\n",
      "rounds_data: new best accuracy: 0.7890458106994629, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 300\n",
      "rounds_data: new best accuracy: 0.7899015545845032, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 128, epochs: 500\n",
      "rounds_data: new best accuracy: 0.7941805720329285, learning rate: 0.001, dropout rate: 0.3, l2: 0.001, batch size: 32, epochs: 750\n",
      "rounds_data: new best accuracy: 0.7958921790122986, learning rate: 0.001, dropout rate: 0.3, l2: 0.0001, batch size: 64, epochs: 500\n",
      "rounds_data: new best accuracy: 0.8040222525596619, learning rate: 0.0005, dropout rate: 0.3, l2: 0.001, batch size: 64, epochs: 1000\n",
      "Dataset: rounds_data, Accuracy: 0.7762088179588318, Best_LR: 0.0005, Best_Dropout: 0.3, Best_L2: 0.001, Best_BS: 64, Best_Epochs: 1000, Duration: 5152.209149837494\n",
      "rounds_data_with_stats: new best accuracy: 0.7599486708641052, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 100\n",
      "rounds_data_with_stats: new best accuracy: 0.7689345479011536, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 200\n",
      "rounds_data_with_stats: new best accuracy: 0.7719298005104065, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 300\n",
      "rounds_data_with_stats: new best accuracy: 0.7881900072097778, learning rate: 0.001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 500\n",
      "rounds_data_with_stats: new best accuracy: 0.7899015545845032, learning rate: 0.001, dropout rate: 0.3, l2: 0.0001, batch size: 32, epochs: 750\n",
      "rounds_data_with_stats: new best accuracy: 0.7924689650535583, learning rate: 0.001, dropout rate: 0.4, l2: 0.01, batch size: 128, epochs: 300\n",
      "rounds_data_with_stats: new best accuracy: 0.7928968667984009, learning rate: 0.0005, dropout rate: 0.4, l2: 0.001, batch size: 32, epochs: 750\n",
      "rounds_data_with_stats: new best accuracy: 0.7937526702880859, learning rate: 0.0005, dropout rate: 0.5, l2: 0.001, batch size: 128, epochs: 100\n",
      "rounds_data_with_stats: new best accuracy: 0.7958921790122986, learning rate: 0.0001, dropout rate: 0.3, l2: 0.01, batch size: 32, epochs: 100\n",
      "rounds_data_with_stats: new best accuracy: 0.7976037859916687, learning rate: 0.0001, dropout rate: 0.3, l2: 0.01, batch size: 64, epochs: 200\n",
      "rounds_data_with_stats: new best accuracy: 0.8014548420906067, learning rate: 0.0001, dropout rate: 0.3, l2: 0.01, batch size: 128, epochs: 300\n",
      "Dataset: rounds_data_with_stats, Accuracy: 0.7903294563293457, Best_LR: 0.0001, Best_Dropout: 0.3, Best_L2: 0.01, Best_BS: 128, Best_Epochs: 300, Duration: 4999.848984003067\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "for X, y, ds_name in datasets:\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "    best_acc = 0\n",
    "    best_lr = 0\n",
    "    best_dropout = 0\n",
    "    best_l2 = 0\n",
    "    best_batch_size = 0\n",
    "    best_epochs = 0\n",
    "    time_start = time()\n",
    "    for lr in learning_rate:\n",
    "        for dr in dropout_rate:\n",
    "            for l2_r in l2_reg:\n",
    "                for bs in batch_size:\n",
    "                    for ep in epochs:\n",
    "                        model = Sequential()\n",
    "                        model.add(Input(shape=(X_train.shape[1],)))\n",
    "                        model.add(Dense(128, activation='relu', kernel_regularizer=l2(l2_r)))\n",
    "                        model.add(Dropout(dr))\n",
    "                        model.add(Dense(64, activation='relu', kernel_regularizer=l2(l2_r)))\n",
    "                        model.add(Dropout(dr))\n",
    "                        model.add(Dense(32, activation='relu', kernel_regularizer=l2(l2_r)))\n",
    "                        model.add(Dropout(dr))\n",
    "                        model.add(Dense(1, activation='sigmoid'))\n",
    "                        optimizer = Adam(learning_rate=lr)\n",
    "                        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "                        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "                        model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=bs, epochs=ep, callbacks=[es], verbose=0)\n",
    "                        _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "                        if acc > best_acc:\n",
    "                            print(f\"{ds_name}: new best accuracy: {acc}, learning rate: {lr}, dropout rate: {dr}, l2: {l2_r}, batch size: {bs}, epochs: {ep}\")\n",
    "                            best_acc = acc\n",
    "                            best_lr = lr\n",
    "                            best_dropout = dr\n",
    "                            best_l2 = l2_r\n",
    "                            best_batch_size = bs\n",
    "                            best_epochs = ep\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(best_l2)))\n",
    "    model.add(Dropout(best_dropout))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(best_l2)))\n",
    "    model.add(Dropout(best_dropout))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(best_l2)))\n",
    "    model.add(Dropout(best_dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(learning_rate=best_lr)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=best_batch_size, epochs=best_epochs, callbacks=[es], verbose=0)\n",
    "\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    best_params.append((ds_name, best_lr, best_dropout, best_l2, best_batch_size, best_epochs, acc))\n",
    "    print(f\"Dataset: {ds_name}, Accuracy: {acc}, Best_LR: {best_lr}, Best_Dropout: {best_dropout}, Best_L2: {best_l2}, Best_BS: {best_batch_size}, Best_Epochs: {best_epochs}, Duration: {time_end - time_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: match_data, Accuracy: 0.6203522682189941, Best_LR: 0.001, Best_Dropout: 0.5, Best_L2: 0.0001, Best_BS: 64, Best_Epochs: 500\n",
      "Dataset: rounds_data, Accuracy: 0.7762088179588318, Best_LR: 0.0005, Best_Dropout: 0.3, Best_L2: 0.001, Best_BS: 64, Best_Epochs: 1000\n",
      "Dataset: rounds_data_with_stats, Accuracy: 0.7903294563293457, Best_LR: 0.0001, Best_Dropout: 0.3, Best_L2: 0.01, Best_BS: 128, Best_Epochs: 300\n"
     ]
    }
   ],
   "source": [
    "for ds_name, best_lr, best_dropout, best_l2, best_batch_size, best_epochs, acc in best_params:\n",
    "    print(f\"Dataset: {ds_name}, Accuracy: {acc}, Best_LR: {best_lr}, Best_Dropout: {best_dropout}, Best_L2: {best_l2}, Best_BS: {best_batch_size}, Best_Epochs: {best_epochs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
