{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, x):\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        probs = np.bincount(k_nearest_labels, minlength=np.max(self.y_train)+1) / self.k\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/match_data.csv')\n",
    "X = df.drop(columns=['Date', 'Team1', 'Team2', 'Score'])\n",
    "y = df['Score']\n",
    "y = y.to_numpy()\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_rounds_data.csv')\n",
    "df = df.drop(columns=[f'player_{i}_{suffix}' for i in range(1, 11) for suffix in ['team_name', 'name']])\n",
    "X = df.drop(['round_winner'], axis=1)\n",
    "y = df['round_winner']\n",
    "y = y.to_numpy()\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_rounds_data_with_stats.csv')\n",
    "df = df.drop(columns=[f'player_{i}_{suffix}' for i in range(1, 11) for suffix in ['team_name', 'name']])\n",
    "X = df.drop(columns=['round_winner'])\n",
    "y = df['round_winner']\n",
    "y = y.to_numpy()\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200, 250, 300, 350, 400, 450, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5, Accuracy: 0.688622754491018\n",
      "K: 10, Accuracy: 0.7095808383233533\n",
      "K: 20, Accuracy: 0.7198460222412318\n",
      "K: 30, Accuracy: 0.7301112061591104\n",
      "K: 40, Accuracy: 0.7395209580838323\n",
      "K: 50, Accuracy: 0.7446535500427716\n",
      "K: 60, Accuracy: 0.7489307100085543\n",
      "K: 70, Accuracy: 0.7532078699743371\n",
      "K: 80, Accuracy: 0.7557741659538066\n",
      "K: 90, Accuracy: 0.7527801539777588\n",
      "K: 100, Accuracy: 0.7510692899914457\n",
      "K: 150, Accuracy: 0.7549187339606501\n",
      "K: 200, Accuracy: 0.7591958939264328\n",
      "K: 250, Accuracy: 0.7557741659538066\n",
      "K: 300, Accuracy: 0.7544910179640718\n",
      "K: 350, Accuracy: 0.7557741659538066\n",
      "K: 400, Accuracy: 0.7467921300256629\n",
      "K: 450, Accuracy: 0.7476475620188195\n",
      "K: 500, Accuracy: 0.7455089820359282\n"
     ]
    }
   ],
   "source": [
    "best_k = 0\n",
    "best_accuracy = 0\n",
    "for k in K:\n",
    "    knn = KNN(k=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = [knn.predict(x) for x in X_val]\n",
    "    print(f'K: {k}, Accuracy: {metrics.accuracy_score(y_val, y_pred)}')\n",
    "    if metrics.accuracy_score(y_val, y_pred) > best_accuracy:\n",
    "        best_accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "        best_k = k\n",
    "\n",
    "knn = KNN(k=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = [knn.predict(x) for x in X_test]\n",
    "print(f'Best K: {best_k}, Accuracy: {metrics.accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 200, Accuracy: 0.7697903294822422\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(k=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = [knn.predict(x) for x in X_test]\n",
    "print(f'Best K: {best_k}, Accuracy: {metrics.accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 5, Best Accuracy: 0.5949119373776908\n"
     ]
    }
   ],
   "source": [
    "print(f'Best K: {best_k}, Best Accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR MATCH DATA BEST ACCURACY WAS FOUND FOR 250 NEIGHBORS\n",
    "Best K: 5, Best Accuracy: 0.5949119373776908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ROUNDS DATA BEST ACCURACY WAS FOUND FOR 250 NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ROUNDS DATA WITH STATS BEST ACCURACY WAS FOUND FOR 250 NEIGHBORS\n",
    "Best K: 250, Best Accuracy: 0.7497861420017109"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
